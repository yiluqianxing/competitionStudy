{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "np.random.seed(1000)\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.643243, 25.470019, 28.443487, 18.739014, 46.749256, 24.096496,\n",
       "       31.391189, 15.830204, 21.105665, 12.702276, 25.97343 , 46.171563,\n",
       "       20.837093, 26.604365, 14.239824, 23.848273, 26.293446, 20.769526,\n",
       "       14.181927, 19.142902, 14.472526, 26.5425  , 20.274246, 31.920924,\n",
       "       11.815633, 19.939913, 43.08211 , 24.73994 , 21.313406, 10.963798,\n",
       "       29.066465,  8.713377, 12.178138, 23.835774, 44.949629, 24.627297,\n",
       "        8.607721, 43.27106 , 22.334295, 13.7788  , 23.273812, 18.728429,\n",
       "       20.404108, 20.801899, 20.960751, 32.759037, 26.422301, 14.175655,\n",
       "       41.757481, 16.658848, 19.088601])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load boston dataset from sklearn\n",
    "data = load_boston()\n",
    "# print(data)\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "# create dataset\n",
    "dataset = Dataset(X_train,y_train,X_test)\n",
    "\n",
    "# initialize RandomForest & LinearRegression \n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "\n",
    "# Stack two models \n",
    "# Returns new dataset with out-of-fold predictions\n",
    "pipeline = ModelsPipeline(model_rf,model_lr)\n",
    "stack_ds = pipeline.stack(k=10,seed=111)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression)\n",
    "results = stacker.predict()\n",
    "results\n",
    "# Validate results using 10 fold cross-validation\n",
    "# results = stacker.validate(k=10,scorer=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Regressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-190fe44e1e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Train LinearRegression on stacked data (second stage)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mstacker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstack_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Regressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "##事先将特征保存到文件中，比较重要，因为jupyter notebook随时会挂掉(⊙_⊙)\n",
    "train = pd.read_csv(\"../dealinput/train2ok.csv\")\n",
    "test = pd.read_csv(\"../dealinput/test2ok.csv\")\n",
    "\n",
    "# train = pd.read_csv('train_part_76_features.csv')\n",
    "# test = pd.read_csv('test_part_76_features.csv')\n",
    "col = [c for c in train if c not in ['id','target']]\n",
    "X_train = train[col]\n",
    "y_train = train['target'].values \n",
    "X_test = test.iloc[:,1:]\n",
    "\"\"\"\n",
    "##使用基于距离的回归方法需要归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train[col] = scaler.fit_transform(X_train)\n",
    "X_test[col] = scaler.fit_transform(X_test)\n",
    "\"\"\"\n",
    "dataset = Dataset(X_train,y_train,X_test)\n",
    "model_gbrt = Classifier(dataset=dataset, estimator=GradientBoostingClassifier,\n",
    "                        parameters={'learning_rate': 0.01,'random_state':3,\n",
    "                                    'n_estimators':200,'subsample':0.8, \n",
    "                                    'max_depth' :20 },\n",
    "                        name='gbrt')\n",
    "#GradientBoostingRegressor(learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, \n",
    "#                      max_depth =10)\n",
    "#model_knn =  Regressor(dataset=dataset, estimator=KNeighborsRegressor, parameters={'n_jobs': -1,'n_neighbors':3},name='knn')\n",
    "# \n",
    "model_xgbc = Classifier(dataset=dataset, estimator=XGBClassifier, \n",
    "                        parameters={'learning_rate': 0.01,'random_state':3,\n",
    "                                'n_estimators':200 ,'subsample':0.8, \n",
    "                                    'objective': 'reg:linear','max_depth' :10},\n",
    "                        name='xgb')\n",
    "#model_mlp =  Regressor(dataset=dataset, estimator=MLPRegressor, parameters={'hidden_layer_sizes': 10,'random_state':9},name='mlp')\n",
    "# initialize RandomForest & LinearRegression\n",
    "model_rf = Classifier(dataset=dataset, estimator=RandomForestClassifier,\n",
    "                      parameters={'n_estimators': 50},name='rf')\n",
    "#model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "\n",
    "\n",
    "# Stack two models\n",
    "# Returns new dataset with out-of-fold predictions\n",
    "pipeline = ModelsPipeline(model_rf,model_xgbc)\n",
    "stack_ds = pipeline.stack(k=5,seed=9)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LogisticRegression)\n",
    "results = stacker.predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
