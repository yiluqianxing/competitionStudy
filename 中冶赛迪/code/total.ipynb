{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0         1    2    3    4    5    6    7      8      9   ...   239  240  \\\n",
      "0    1  0.970149    0    1    0    0    0 -666 -888.0 -888.0 ...   NaN  NaN   \n",
      "1    1  0.970149    1    1    1    0    0 -888 -888.0 -888.0 ...   NaN  NaN   \n",
      "2    2  0.835821    2    1    2    0    0 -888 -888.0 -888.0 ...   NaN  NaN   \n",
      "3    2  0.119403    3    1    3    0    0 -666 -666.0 -666.0 ...   NaN  NaN   \n",
      "4    2  0.119403    4    1    0    0    1 -666 -666.0    9.0 ...   NaN  NaN   \n",
      "\n",
      "   241  242  243  244  245  246  247  248  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 249 columns]\n",
      ".............\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(             1    2   3   4   5   6    7      8      9      10  ...       46  \\\n",
       " 0      0.970149    0   1   0   0   0 -666 -888.0 -888.0 -888.0  ...   -888.0   \n",
       " 1      0.970149    1   1   1   0   0 -888 -888.0 -888.0 -888.0  ...   -888.0   \n",
       " 2      0.835821    2   1   2   0   0 -888 -888.0 -888.0 -888.0  ...   -888.0   \n",
       " 3      0.119403    3   1   3   0   0 -666 -666.0 -666.0 -666.0  ...   -666.0   \n",
       " 4      0.119403    4   1   0   0   1 -666 -666.0    9.0    9.0  ...      9.0   \n",
       " 5      0.268657    5   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 6      0.268657    6   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 7      0.268657    7   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 8      0.268657    8   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 9      0.268657    9   1   0   0   1 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 10     0.268657   10   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 11     0.268657   11   1   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 12     0.268657   12   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 13     0.253731   13   2   0   0   0 -666    8.0    8.0    8.0  ...      8.0   \n",
       " 14     0.268657   14   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 15     0.268657   15   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 16     0.268657   16   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 17     0.268657   17   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 18     0.268657   18   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 19     0.268657   19   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 20     0.268657   20   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 21     0.268657   21   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 22     0.268657   22   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 23     0.268657   23   2   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 24     0.268657   24   3   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 25     0.253731   25   3   0   0   0 -666    8.0    8.0    8.0  ...      8.0   \n",
       " 26     0.268657   26   3   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 27     0.268657   27   3   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 28     0.268657   28   3   0   0   0 -888    8.0    8.0    8.0  ...      8.0   \n",
       " 29     0.746269   29   3  -1   0   0 -666 -888.0 -666.0 -666.0  ...   -888.0   \n",
       " ...         ...  ...  ..  ..  ..  ..  ...    ...    ...    ...  ...      ...   \n",
       " 56680  0.750000  298   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56681  0.759615  299   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56682  0.740385  300   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56683  0.730769  301   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56684  0.740385  302   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56685  0.730769  303   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56686  0.750000  304   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56687  0.740385  305   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56688  0.740385  306   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56689  0.750000  307   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56690  0.750000  308   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56691  0.759615  309   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56692  0.778846  310   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56693  0.778846  311   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56694  0.769231  312   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56695  0.769231  313   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56696  0.750000  314   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56697  0.721154  315   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56698  0.769231  316   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56699  0.740385  317   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56700  0.750000  318   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56701  0.750000  319   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56702  0.759615  320   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56703  0.778846  321   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56704  0.798077  322   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " 56705  0.927711    0   1   0   1   0 -666 -888.0 -888.0 -888.0  ...   -888.0   \n",
       " 56706  0.168675    1   2   1   0   0 -666 -666.0 -666.0 -666.0  ...   -666.0   \n",
       " 56707  0.072289    2   2   2   0   0 -666 -666.0 -666.0 -666.0  ...   -666.0   \n",
       " 56708  0.000000    3   3   3   0   0 -666 -666.0 -666.0 -666.0  ...   -666.0   \n",
       " 56709  0.759036    4   3   0   0   0    8    8.0    8.0 -666.0  ...   -888.0   \n",
       " \n",
       "           47     48     49     50     51     52     53     54     55  \n",
       " 0     -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 1     -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 2     -666.0 -888.0 -888.0 -888.0 -888.0 -888.0 -666.0 -888.0 -666.0  \n",
       " 3     -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0  \n",
       " 4        9.0    9.0    9.0    9.0    9.0    9.0    9.0    8.0    9.0  \n",
       " 5        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 6        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 7        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 8        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 9        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 10       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 11       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 12       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 13       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 14       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 15       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 16       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 17       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 18       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 19       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 20       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 21       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 22       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 23       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 24       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 25       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 26       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 27       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 28       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 29    -888.0 -888.0 -888.0 -888.0 -888.0 -666.0 -888.0 -888.0 -888.0  \n",
       " ...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       " 56680 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56681 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56682 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56683 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56684 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56685 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56686 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56687 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56688 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56689 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56690 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56691 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56692 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56693 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 56694 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56695 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56696 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56697 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56698 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56699 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56700 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56701 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0 -888.0    8.0  \n",
       " 56702 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 56703 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 56704 -888.0 -888.0    8.0    8.0 -888.0 -888.0 -888.0    8.0    8.0  \n",
       " 56705 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 56706 -666.0 -666.0 -666.0 -666.0 -666.0 -888.0 -666.0 -666.0 -666.0  \n",
       " 56707 -666.0 -666.0 -666.0 -666.0 -666.0 -888.0 -666.0 -666.0 -666.0  \n",
       " 56708 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0  \n",
       " 56709 -888.0 -888.0 -888.0 -888.0    8.0 -888.0 -888.0 -888.0 -888.0  \n",
       " \n",
       " [56710 rows x 55 columns],\n",
       "              1    2   3   4   5   6    7    8      9      10  ...       46  \\\n",
       " 0      0.970149    0   1   0   0   0 -666 -888 -888.0 -888.0  ...   -888.0   \n",
       " 1      0.970149    1   1   1   0   0 -888 -888 -888.0 -888.0  ...   -888.0   \n",
       " 2      0.835821    2   1   2   0   0 -888 -888 -888.0 -888.0  ...   -888.0   \n",
       " 3      0.119403    3   1   3   0   0 -666 -666 -666.0 -666.0  ...   -666.0   \n",
       " 4      0.119403    4   1   0   0   1 -666 -666    9.0    9.0  ...      9.0   \n",
       " 5      0.268657    5   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 6      0.268657    6   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 7      0.268657    7   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 8      0.268657    8   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 9      0.268657    9   1   0   0   1 -888    8    8.0    8.0  ...      8.0   \n",
       " 10     0.268657   10   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 11     0.268657   11   1   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 12     0.268657   12   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 13     0.253731   13   2   0   0   0 -666    8    8.0    8.0  ...      8.0   \n",
       " 14     0.268657   14   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 15     0.268657   15   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 16     0.268657   16   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 17     0.268657   17   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 18     0.268657   18   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 19     0.268657   19   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 20     0.268657   20   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 21     0.268657   21   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 22     0.268657   22   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 23     0.268657   23   2   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 24     0.268657   24   3   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 25     0.253731   25   3   0   0   0 -666    8    8.0    8.0  ...      8.0   \n",
       " 26     0.268657   26   3   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 27     0.268657   27   3   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 28     0.268657   28   3   0   0   0 -888    8    8.0    8.0  ...      8.0   \n",
       " 29     0.746269   29   3  -1   0   0 -666 -888 -666.0 -666.0  ...   -888.0   \n",
       " ...         ...  ...  ..  ..  ..  ..  ...  ...    ...    ...  ...      ...   \n",
       " 19434  0.746988  681   3   0   0   0    8    8    8.0 -666.0  ...   -888.0   \n",
       " 19435  0.759036  682   3   0   0   0    8    8    8.0 -666.0  ...   -888.0   \n",
       " 19436  0.734940  683   3   0   0   0    8    8    8.0 -666.0  ...   -888.0   \n",
       " 19437  0.626506  684   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19438  0.614458  685   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19439  0.614458  686   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19440  0.650602  687   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19441  0.614458  688   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19442  0.638554  689   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19443  0.650602  690   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19444  0.674699  691   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19445  0.590361  692   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19446  0.662651  693   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19447  0.614458  694   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19448  0.674699  695   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19449  0.650602  696   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19450  0.614458  697   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19451  0.734940  698   3   0   0   0    8    8    8.0 -666.0  ...   -888.0   \n",
       " 19452  0.746988  699   3   0   0   0    8    8    8.0 -666.0  ...   -888.0   \n",
       " 19453  0.614458  700   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19454  0.602410  701   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19455  0.638554  702   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19456  0.638554  703   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19457  0.638554  704   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19458  0.602410  705   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19459  0.674699  706   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19460  0.638554  707   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19461  0.614458  708   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19462  0.614458  709   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " 19463  0.626506  710   3   0   0   0    8    8    8.0 -666.0  ...      8.0   \n",
       " \n",
       "           47     48     49     50     51     52     53     54     55  \n",
       " 0     -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 1     -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 2     -666.0 -888.0 -888.0 -888.0 -888.0 -888.0 -666.0 -888.0 -666.0  \n",
       " 3     -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0 -666.0  \n",
       " 4        9.0    9.0    9.0    9.0    9.0    9.0    9.0    8.0    9.0  \n",
       " 5        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 6        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 7        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 8        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 9        8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 10       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 11       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 12       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 13       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 14       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 15       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 16       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 17       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 18       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 19       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 20       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 21       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 22       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 23       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 24       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 25       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 26       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 27       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 28       8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0    8.0  \n",
       " 29    -888.0 -888.0 -888.0 -888.0 -888.0 -666.0 -888.0 -888.0 -888.0  \n",
       " ...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       " 19434 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 19435 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 19436 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 19437 -888.0    8.0 -888.0    8.0 -888.0 -888.0    8.0    8.0 -888.0  \n",
       " 19438    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0 -888.0  \n",
       " 19439    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0    8.0  \n",
       " 19440    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0 -888.0  \n",
       " 19441    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19442    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19443    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0 -888.0  \n",
       " 19444    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19445    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0    8.0  \n",
       " 19446    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0 -888.0  \n",
       " 19447    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19448    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19449    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19450    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0    8.0    8.0  \n",
       " 19451 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 19452 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0 -888.0  \n",
       " 19453    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19454    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19455    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19456    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19457    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19458    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19459    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19460    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19461    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0 -888.0  \n",
       " 19462    8.0 -888.0 -888.0    8.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " 19463    8.0 -888.0 -888.0 -888.0 -888.0 -888.0    8.0 -888.0    8.0  \n",
       " \n",
       " [19464 rows x 55 columns])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =  pd.read_csv(\"../trainFullNumberNew88.csv\",encoding = \"utf-8\",header = None)\n",
    "validata =  pd.read_csv(\"../validataFullNumberNew88.csv\",encoding = \"utf-8\",header = None)\n",
    "print(train.head())\n",
    "print(\".............\")\n",
    "l = 56  #54 维\n",
    "trainx = train.iloc[:,1:l]\n",
    "trainy = train.iloc[:,0]\n",
    "\n",
    "validatax = validata.iloc[:,1:l]\n",
    "validatay = validata.iloc[:,0]\n",
    "trainx,validatax\n",
    "#(array([0.18, 0.11, 0.18, 0.15, 0.03, 0.11, 0.08, 0.09, 0.01, 0.06]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainx.isnull().sum(),validatax.isnull().sum().sort_values(ascending = False)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 11    0\n",
       " 12    0\n",
       " 13    0\n",
       " 14    0\n",
       " 15    0\n",
       " 16    0\n",
       " 17    0\n",
       " 18    0\n",
       " 19    0\n",
       " 20    0\n",
       " 21    0\n",
       " 22    0\n",
       " 23    0\n",
       " 24    0\n",
       " 25    0\n",
       " 26    0\n",
       " 27    0\n",
       " 28    0\n",
       " 29    0\n",
       " 30    0\n",
       " 31    0\n",
       " 32    0\n",
       " 33    0\n",
       " 34    0\n",
       " 35    0\n",
       " 36    0\n",
       " 37    0\n",
       " 38    0\n",
       " 39    0\n",
       " 40    0\n",
       " 41    0\n",
       " 42    0\n",
       " 43    0\n",
       " 44    0\n",
       " 45    0\n",
       " 46    0\n",
       " 47    0\n",
       " 48    0\n",
       " 49    0\n",
       " 50    0\n",
       " 51    0\n",
       " 52    0\n",
       " 53    0\n",
       " 54    0\n",
       " 55    0\n",
       " dtype: int64, 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 11    0\n",
       " 12    0\n",
       " 13    0\n",
       " 14    0\n",
       " 15    0\n",
       " 16    0\n",
       " 17    0\n",
       " 18    0\n",
       " 19    0\n",
       " 20    0\n",
       " 21    0\n",
       " 22    0\n",
       " 23    0\n",
       " 24    0\n",
       " 25    0\n",
       " 26    0\n",
       " 27    0\n",
       " 28    0\n",
       " 29    0\n",
       " 30    0\n",
       " 31    0\n",
       " 32    0\n",
       " 33    0\n",
       " 34    0\n",
       " 35    0\n",
       " 36    0\n",
       " 37    0\n",
       " 38    0\n",
       " 39    0\n",
       " 40    0\n",
       " 41    0\n",
       " 42    0\n",
       " 43    0\n",
       " 44    0\n",
       " 45    0\n",
       " 46    0\n",
       " 47    0\n",
       " 48    0\n",
       " 49    0\n",
       " 50    0\n",
       " 51    0\n",
       " 52    0\n",
       " 53    0\n",
       " 54    0\n",
       " 55    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.fillna(-888,inplace = True)\n",
    "validatax.fillna(-888,inplace = True)\n",
    "trainx.isnull().sum(),validatax.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56710, 55), (19464, 55))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx[trainx == -888] = 3\n",
    "trainx[trainx == -666] = 4\n",
    "trainx[trainx == 8] = 5\n",
    "\n",
    "validatax[validatax == -888] = 3\n",
    "validatax[validatax == -666] = 4\n",
    "validatax[validatax == 8] = 5\n",
    "trainx.shape,validatax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991183212837242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987656497972139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985893140539588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987068712161289\n",
      "0.9985305354728737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.64e-02, 1.44e-01, 4.93e-02, 8.59e-02, 1.22e-03, 3.95e-04,\n",
       "       3.13e-02, 1.11e-01, 4.55e-02, 9.48e-03, 2.57e-02, 9.53e-02,\n",
       "       8.21e-02, 8.57e-03, 7.19e-03, 6.90e-03, 1.04e-02, 1.14e-02,\n",
       "       9.92e-03, 2.99e-02, 3.53e-02, 7.47e-03, 4.67e-02, 1.33e-02,\n",
       "       1.66e-03, 3.64e-03, 2.56e-03, 2.55e-03, 3.50e-03, 5.39e-03,\n",
       "       1.73e-03, 1.20e-02, 9.34e-04, 4.72e-03, 2.49e-03, 4.66e-04,\n",
       "       2.96e-03, 6.64e-03, 2.79e-03, 2.52e-03, 7.41e-03, 7.25e-04,\n",
       "       2.40e-03, 1.58e-03, 2.20e-04, 3.29e-04, 1.44e-03, 4.03e-04,\n",
       "       9.71e-04, 9.87e-04, 4.23e-03, 1.45e-02, 1.80e-03, 1.46e-03,\n",
       "       1.10e-04])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "accuracyMean = 0\n",
    "for i in range(1,6):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(trainx,trainy,test_size = 0.3,random_state=i)\n",
    "    rf0.fit(x_train,y_train)\n",
    "    pre = rf0.predict(x_test)\n",
    "    mm = accuracy_score(pre,y_test)\n",
    "    print(mm) \n",
    "    accuracyMean = mm\n",
    "    label = train.columns\n",
    "    importances = rf0.feature_importances_\n",
    "importances\n",
    "#  没有替换为3，4，5  得分  0.9927114559454535   替换后：0.9927114559454535  加特征之前\n",
    "# 0.9965320637159819  加特征以后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 1 0.9985893140539588\n",
      "None [0.96 0.97 1.   0.99]\n",
      "f1 1 0.9985893140539588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 2 0.9982954211485334\n",
      "None [0.93 0.97 1.   0.99]\n",
      "f1 2 0.9982954211485334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 3 0.9983541997296185\n",
      "None [0.93 0.97 1.   0.99]\n",
      "f1 3 0.9983541997296185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 4 0.998824428378299\n",
      "None [0.97 0.98 1.   0.99]\n",
      "f1 4 0.998824428378299\n",
      "acc 5 0.9990595427026392\n",
      "None [0.96 0.98 1.   0.99]\n",
      "f1 5 0.9990595427026392\n",
      "accMean: 0.9986245812026098 f1Mean: 0.9986245812026098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n64维度 特征（i）\\nacc 5 0.997825192499853\\nf1 5 0.997825192499853\\naccMean: 0.997883971080938 f1Mean: 0.997883971080938\\n64维度 特征（1）\\nacc 5 0.9978839710809381\\nf1 5 0.9978839710809381\\naccMean: 0.997860459648504 f1Mean: 0.997860459648504\\n加了字母比文字多的特征列\\nacc 5 0.997766413918768\\nf1 5 0.997766413918768\\naccMean: 0.9977781696349849 f1Mean: 0.9977781696349849\\n加了缺失率\\nacc 5 0.9980603068241932\\nf1 5 0.9980603068241932\\naccMean: 0.9982954211485335 f1Mean: 0.9982954211485335\\n最有参数和数据集\\nacc 5 0.9989419855404691\\nNone [0.95 0.98 1.   0.99]\\nf1 5 0.9989419855404691\\naccMean: 0.9985540469053078 f1Mean: 0.9985540469053078\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score \n",
    "accMean = 0\n",
    "f1Mean = 0\n",
    "for i in range(1,6):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(trainx,trainy,test_size = 0.3,random_state=i+100)\n",
    "    xgb1 = XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            max_depth=5,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,          #0.866124\t0.008005\t0.965337\t0.002286\n",
    "            seed=1)\n",
    "    xgb1.fit(x_train,y_train)\n",
    "    prexgb = xgb1.predict(x_test)\n",
    "    aa = accuracy_score(prexgb,y_test)\n",
    "    print(\"acc\",i,aa) \n",
    "    cc = f1_score (prexgb,y_test, average='micro')\n",
    "    print(\"None\",f1_score (prexgb,y_test, average=None))\n",
    "    print(\"f1\",i,cc)\n",
    "    accMean += aa\n",
    "    f1Mean += cc\n",
    "print(\"accMean:\",accMean/5,\"f1Mean:\",f1Mean/5)\n",
    "\n",
    "# 加特征之前\n",
    "# 没有替换1，2，3，4 得分 (0.9930772780883032, array([0.63, 0.89, 1.  , 0.97]))\n",
    "#替换后：(0.9930772780883032, array([0.63, 0.89, 1.  , 0.97]))   说明替换与否不影响\n",
    "# 加特征后\n",
    "#(0.9974360289215938, array([0.88328076, 0.94982079, 0.99929794, 0.99176578]))\n",
    "'''\n",
    "64维度 特征（i）\n",
    "acc 5 0.997825192499853\n",
    "f1 5 0.997825192499853\n",
    "accMean: 0.997883971080938 f1Mean: 0.997883971080938\n",
    "64维度 特征（1）\n",
    "acc 5 0.9978839710809381\n",
    "f1 5 0.9978839710809381\n",
    "accMean: 0.997860459648504 f1Mean: 0.997860459648504\n",
    "加了字母比文字多的特征列\n",
    "acc 5 0.997766413918768\n",
    "f1 5 0.997766413918768\n",
    "accMean: 0.9977781696349849 f1Mean: 0.9977781696349849\n",
    "加了缺失率\n",
    "acc 5 0.9980603068241932\n",
    "f1 5 0.9980603068241932\n",
    "accMean: 0.9982954211485335 f1Mean: 0.9982954211485335\n",
    "最有参数和数据集\n",
    "acc 5 0.9989419855404691\n",
    "None [0.95 0.98 1.   0.99]\n",
    "f1 5 0.9989419855404691\n",
    "accMean: 0.9985540469053078 f1Mean: 0.9985540469053078\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56710, 55) (56710,) (19464, 55) (19464,)\n",
      "acc 0.9991779695848746\n",
      "f1 0.9881463514295148\n",
      "[0.97 0.99 1.   1.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n不要第一列\\nacc 0.9966668375980718\\nf1 0.9966668375980718\\narray([0.89296636, 0.9540636 , 0.99891909, 0.97370807])\\n要第一列 (20行)\\nacc 0.9978975437157069\\nf1 0.9978975437157069\\n[0.91082803 0.9664903  0.99929783 0.99176578]\\n(64行)  i\\nacc 0.9985641761960925\\nf1 0.9985641761960925\\n[0.94 0.98 1.   1.  ]\\n（64行） 1\\nacc 0.9984616173529562\\nf1 0.9984616173529562\\n[0.93 0.98 1.   0.99]\\n加了字母比文字多行和缺失率行\\nacc 0.99892108508014\\nf1 0.998921085080148\\n[0.96 0.98 1.   1.  ]\\n缺失率加上，默认参数\\nacc 0.99922934648582\\nf1 0.99922934648582\\n[0.97 0.99 1.   1.  ]\\n最优\\nacc 0.99922934648582\\nf1 0.99922934648582\\n[0.97 0.99 1.   1.  ]\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1)\n",
    "xgb1.fit(trainx,trainy)\n",
    "print(trainx.shape,trainy.shape,validatax.shape,validatay.shape)\n",
    "prexgb = xgb1.predict(validatax)\n",
    "aa = accuracy_score(prexgb,validatay)\n",
    "print(\"acc\",aa) \n",
    "cc = f1_score (prexgb,validatay, average='macro')\n",
    "print(\"f1\",cc)\n",
    "print(f1_score (prexgb,validatay, average=None))\n",
    "''' \n",
    "不要第一列\n",
    "acc 0.9966668375980718\n",
    "f1 0.9966668375980718\n",
    "array([0.89296636, 0.9540636 , 0.99891909, 0.97370807])\n",
    "要第一列 (20行)\n",
    "acc 0.9978975437157069\n",
    "f1 0.9978975437157069\n",
    "[0.91082803 0.9664903  0.99929783 0.99176578]\n",
    "(64行)  i\n",
    "acc 0.9985641761960925\n",
    "f1 0.9985641761960925\n",
    "[0.94 0.98 1.   1.  ]\n",
    "（64行） 1\n",
    "acc 0.9984616173529562\n",
    "f1 0.9984616173529562\n",
    "[0.93 0.98 1.   0.99]\n",
    "加了字母比文字多行和缺失率行\n",
    "acc 0.99892108508014\n",
    "f1 0.998921085080148\n",
    "[0.96 0.98 1.   1.  ]\n",
    "缺失率加上，默认参数\n",
    "acc 0.99922934648582\n",
    "f1 0.99922934648582\n",
    "[0.97 0.99 1.   1.  ]\n",
    "最优\n",
    "acc 0.99922934648582\n",
    "f1 0.99922934648582\n",
    "[0.97 0.99 1.   1.  ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cmap = plt.cm.binary\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tick_marks = np.array(range(len(labels))) + 0.5\n",
    "    np.set_printoptions(precision=2)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 8), dpi=120)\n",
    "    ind_array = np.arange(len(labels))\n",
    "    x, y = np.meshgrid(ind_array, ind_array)\n",
    "    intFlag = 0 # 标记在图片中对文字是整数型还是浮点型\n",
    "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
    "        #\n",
    "\n",
    "        if (intFlag):\n",
    "            c = cm[y_val][x_val]\n",
    "            plt.text(x_val, y_val, \"%d\" % (c,), color='red', fontsize=8, va='center', ha='center')\n",
    "\n",
    "        else:\n",
    "            c = cm_normalized[y_val][x_val]\n",
    "            if (c > 0.0001):\n",
    "                #这里是绘制数字，可以对数字大小和颜色进行修改\n",
    "                plt.text(x_val, y_val, \"%0.2f\" % (c,), color='red', fontsize=7, va='center', ha='center')\n",
    "            else:\n",
    "                plt.text(x_val, y_val, \"%d\" % (0,), color='red', fontsize=7, va='center', ha='center')\n",
    "    if(intFlag):\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "    plt.gca().set_xticks(tick_marks, minor=True)\n",
    "    plt.gca().set_yticks(tick_marks, minor=True)\n",
    "    plt.gca().xaxis.set_ticks_position('none')\n",
    "    plt.gca().yaxis.set_ticks_position('none')\n",
    "    plt.grid(True, which='minor', linestyle='-')\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.title('')\n",
    "    plt.colorbar()\n",
    "    xlocations = np.array(range(len(labels)))\n",
    "    plt.xticks(xlocations, labels, rotation=90)\n",
    "    plt.yticks(xlocations, labels)\n",
    "    plt.ylabel('Index of True Classes')\n",
    "    plt.xlabel('Index of Predict Classes')\n",
    "#     plt.savefig('confusion_matrix.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  144     2     0     0]\n",
      " [    2   282     0     0]\n",
      " [    5     4 18488     1]\n",
      " [    0     0     2   534]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x960 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my_confusion_matrix(pre,y_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = [1,2,3,4]\n",
    "print(confusion_matrix(prexgb,validatay))\n",
    "plot_confusion_matrix(prexgb,validatay,labels)\n",
    "\n",
    "#20行  0.89，0.99，1，0.99\n",
    "#64（i）0.93,0.99,1,0.99\n",
    "#全部特征，未调优： 0.97，0.99，1，0.99  19464 个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#参数调优\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from matplotlib import  pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([13.85, 14.79, 13.89]),\n",
       " 'score_time': array([0.37, 0.51, 0.57]),\n",
       " 'test_precision_macro': array([0.91, 0.94, 0.96]),\n",
       " 'test_recall_macro': array([0.78, 0.92, 0.94])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "# scores = cross_val_score(xgb1, trainx, trainy, cv=3, scoring='f1_macro') \n",
    "scores = cross_validate(xgb1, trainx, trainy, scoring=scoring,cv=3, return_train_score=False)\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.89552, std: 0.05792, params: {'n_estimators': 75},\n",
       "  mean: 0.89558, std: 0.05784, params: {'n_estimators': 76},\n",
       "  mean: 0.89558, std: 0.05784, params: {'n_estimators': 77},\n",
       "  mean: 0.89535, std: 0.05787, params: {'n_estimators': 78},\n",
       "  mean: 0.89550, std: 0.05794, params: {'n_estimators': 79},\n",
       "  mean: 0.89552, std: 0.05792, params: {'n_estimators': 80},\n",
       "  mean: 0.89559, std: 0.05799, params: {'n_estimators': 81},\n",
       "  mean: 0.89559, std: 0.05799, params: {'n_estimators': 82},\n",
       "  mean: 0.89565, std: 0.05790, params: {'n_estimators': 83},\n",
       "  mean: 0.89558, std: 0.05784, params: {'n_estimators': 84}],\n",
       " {'n_estimators': 83},\n",
       " 0.8956543269445283)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'n_estimators':range(75,85,1),\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test1, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch1.fit(trainx,trainy)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.83301, std: 0.06378, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.83835, std: 0.06034, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.84049, std: 0.05914, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.89696, std: 0.05471, params: {'max_depth': 3, 'min_child_weight': 7},\n",
       "  mean: 0.83552, std: 0.06099, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.84667, std: 0.05545, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.89565, std: 0.05790, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.89700, std: 0.05513, params: {'max_depth': 5, 'min_child_weight': 7},\n",
       "  mean: 0.85639, std: 0.05560, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.84716, std: 0.05982, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.89665, std: 0.05746, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.89668, std: 0.05394, params: {'max_depth': 7, 'min_child_weight': 7},\n",
       "  mean: 0.85760, std: 0.05465, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.84850, std: 0.06008, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.89719, std: 0.05888, params: {'max_depth': 9, 'min_child_weight': 5},\n",
       "  mean: 0.89674, std: 0.05423, params: {'max_depth': 9, 'min_child_weight': 7}],\n",
       " {'max_depth': 9, 'min_child_weight': 5},\n",
       " 0.8971887295973908)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,8,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=83,\n",
    "            max_depth=5,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test1, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch1.fit(trainx,trainy)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.89836, std: 0.05832, params: {'max_depth': 8, 'min_child_weight': 4},\n",
       "  mean: 0.89690, std: 0.05759, params: {'max_depth': 8, 'min_child_weight': 5},\n",
       "  mean: 0.89844, std: 0.05836, params: {'max_depth': 9, 'min_child_weight': 4},\n",
       "  mean: 0.89719, std: 0.05888, params: {'max_depth': 9, 'min_child_weight': 5},\n",
       "  mean: 0.89819, std: 0.05822, params: {'max_depth': 10, 'min_child_weight': 4},\n",
       "  mean: 0.89753, std: 0.05807, params: {'max_depth': 10, 'min_child_weight': 5},\n",
       "  mean: 0.89819, std: 0.05822, params: {'max_depth': 11, 'min_child_weight': 4},\n",
       "  mean: 0.89748, std: 0.05802, params: {'max_depth': 11, 'min_child_weight': 5}],\n",
       " {'max_depth': 9, 'min_child_weight': 4},\n",
       " 0.8984413325504804)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(8,12,1),\n",
    "    'min_child_weight':range(4,6,1)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=83,\n",
    "            max_depth=5,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test1, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch1.fit(trainx,trainy)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.88999, std: 0.06561, params: {'learning_rate': 0.05},\n",
       "  mean: 0.89665, std: 0.06227, params: {'learning_rate': 0.08},\n",
       "  mean: 0.89844, std: 0.05836, params: {'learning_rate': 0.1}],\n",
       " {'learning_rate': 0.1},\n",
       " 0.8984413325504804)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'learning_rate':[0.05,0.08,0.1]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =  XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=83,\n",
    "            max_depth=9,\n",
    "            min_child_weight=4,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test4, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch4.fit(trainx,trainy)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.90078, std: 0.04610, params: {'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "  mean: 0.86134, std: 0.04196, params: {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "  mean: 0.86242, std: 0.04566, params: {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "  mean: 0.85990, std: 0.04951, params: {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "  mean: 0.90140, std: 0.04735, params: {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "  mean: 0.90075, std: 0.05067, params: {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "  mean: 0.90467, std: 0.04798, params: {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "  mean: 0.85248, std: 0.05601, params: {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "  mean: 0.89876, std: 0.05450, params: {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "  mean: 0.89660, std: 0.05705, params: {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "  mean: 0.89844, std: 0.05836, params: {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "  mean: 0.84540, std: 0.06115, params: {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "  mean: 0.89658, std: 0.05846, params: {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "  mean: 0.89469, std: 0.05985, params: {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "  mean: 0.84384, std: 0.06107, params: {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "  mean: 0.89345, std: 0.05874, params: {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       " {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       " 0.904669438720266)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =  XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=83,\n",
    "            max_depth=9,\n",
    "            min_child_weight=4,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test4, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch4.fit(trainx,trainy)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.89790, std: 0.05416, params: {'colsample_bytree': 0.75, 'subsample': 0.65},\n",
       "  mean: 0.89727, std: 0.05643, params: {'colsample_bytree': 0.75, 'subsample': 0.7},\n",
       "  mean: 0.89859, std: 0.05781, params: {'colsample_bytree': 0.75, 'subsample': 0.75},\n",
       "  mean: 0.89594, std: 0.05799, params: {'colsample_bytree': 0.8, 'subsample': 0.65},\n",
       "  mean: 0.89660, std: 0.05705, params: {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "  mean: 0.89793, std: 0.05813, params: {'colsample_bytree': 0.8, 'subsample': 0.75},\n",
       "  mean: 0.89489, std: 0.06096, params: {'colsample_bytree': 0.85, 'subsample': 0.65},\n",
       "  mean: 0.89209, std: 0.05739, params: {'colsample_bytree': 0.85, 'subsample': 0.7},\n",
       "  mean: 0.89607, std: 0.06214, params: {'colsample_bytree': 0.85, 'subsample': 0.75}],\n",
       " {'colsample_bytree': 0.75, 'subsample': 0.75},\n",
       " 0.8985867614966246)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/100.0 for i in range(65,80,5)],\n",
    "    'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =  XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=83,\n",
    "            max_depth=9,\n",
    "            min_child_weight=4,\n",
    "            gamma=0.1,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.8,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test4, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch4.fit(trainx,trainy)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gongju\\python3.6 64\\anzhuang\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.89826, std: 0.05777, params: {'n_estimators': 87},\n",
       "  mean: 0.89826, std: 0.05777, params: {'n_estimators': 88},\n",
       "  mean: 0.89851, std: 0.05792, params: {'n_estimators': 89},\n",
       "  mean: 0.89834, std: 0.05782, params: {'n_estimators': 90},\n",
       "  mean: 0.89809, std: 0.05768, params: {'n_estimators': 91},\n",
       "  mean: 0.89776, std: 0.05750, params: {'n_estimators': 92},\n",
       "  mean: 0.89795, std: 0.05632, params: {'n_estimators': 93},\n",
       "  mean: 0.89842, std: 0.05657, params: {'n_estimators': 94},\n",
       "  mean: 0.89737, std: 0.05729, params: {'n_estimators': 95},\n",
       "  mean: 0.89788, std: 0.05626, params: {'n_estimators': 96},\n",
       "  mean: 0.89714, std: 0.05712, params: {'n_estimators': 97}],\n",
       " {'n_estimators': 89},\n",
       " 0.8985096273283567)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'n_estimators':range(87,98,1)\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =  XGBClassifier(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=89,\n",
    "            max_depth=9,\n",
    "            min_child_weight=4,\n",
    "            gamma=0.1,\n",
    "            subsample=0.75,\n",
    "            colsample_bytree=0.75,\n",
    "            nthread=3,\n",
    "            scale_pos_weight=1,\n",
    "            StratifiedKFold = True,         \n",
    "            seed=1), \n",
    "                       param_grid = param_test4, scoring='f1_macro',n_jobs=3,iid=False, cv=3)\n",
    "gsearch4.fit(trainx,trainy)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
